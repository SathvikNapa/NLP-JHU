{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3b03d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8a0caf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create grammar with terminal, non-terminal hash\n",
    "non_terminal_pattern = r\"^[A-Z]+$\"\n",
    "pre_terminal_pattern = r\"^[A-Za-z]{2,}$\"\n",
    "terminal_pattern = r\"(^[a-z\\s]+)$\"\n",
    "\n",
    "def _spit_probable_choice(items, weights):\n",
    "    return random.choices(items, weights, k=1)[0]\n",
    "\n",
    "grammar_text = open(\"grammar.gr\", \"rb\").read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def _is_non_terminal(text):\n",
    "    return bool(re.search(non_terminal_pattern, text))\n",
    "\n",
    "def _is_pre_terminal(text):\n",
    "    return bool(re.search(pre_terminal_pattern, text))\n",
    "\n",
    "def _is_terminal(text):\n",
    "    return bool(re.search(terminal_pattern, text))\n",
    "\n",
    "def _create_grammar_hash(grammar_text):\n",
    "    def _is_comment(line):\n",
    "        if re.search(r\"^[#\\s()]\", line):\n",
    "            return 1\n",
    "\n",
    "    valid_symbols = list(filter(lambda text: len(text)>1 and not _is_comment(text), grammar_text.split(\"\\n\")))\n",
    "    cleaned_valid_symbols = list(map(lambda line: line.split(\"#\")[0].strip().split(\"\\t\"), valid_symbols))\n",
    "\n",
    "    non_terminal_hash = {}\n",
    "    terminal_hash = {}\n",
    "    for symbol in cleaned_valid_symbols:\n",
    "        if _is_terminal(symbol[2]):\n",
    "            if symbol[1] not in terminal_hash:\n",
    "                terminal_hash[symbol[1]] = {str(symbol[2]): float(symbol[0])}\n",
    "                continue\n",
    "            terminal_hash[symbol[1]].update({str(symbol[2]): float(symbol[0])})\n",
    "            continue\n",
    "        else:\n",
    "            print(symbol)\n",
    "            if symbol[1] not in non_terminal_hash:\n",
    "                non_terminal_hash[symbol[1]] = {tuple(map(str, symbol[2].split())): float(symbol[0])}\n",
    "                continue\n",
    "            non_terminal_hash[symbol[1]].update({tuple(map(str, symbol[2].split())): float(symbol[0])})\n",
    "    merged = non_terminal_hash.copy()\n",
    "    merged.update(terminal_hash)\n",
    "    return terminal_hash, non_terminal_hash, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c65a8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a combined grammar hash\n",
    "\n",
    "non_terminal_pattern = r\"^[A-Z]+$\"\n",
    "pre_terminal_pattern = r\"^[A-Za-z]{2,}$\"\n",
    "terminal_pattern = r\"(^[a-z\\s]+)$\"\n",
    "\n",
    "def _spit_probable_choice(items, weights):\n",
    "    return random.choices(items, weights, k=1)[0]\n",
    "\n",
    "grammar_text = open(\"grammar.gr\", \"rb\").read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def _is_non_terminal(text):\n",
    "    return bool(re.search(non_terminal_pattern, text))\n",
    "\n",
    "def _is_pre_terminal(text):\n",
    "    return bool(re.search(pre_terminal_pattern, text))\n",
    "\n",
    "def _is_terminal(text):\n",
    "    return bool(re.search(terminal_pattern, text))\n",
    "\n",
    "def _create_grammar_hash(grammar_text):\n",
    "    def _is_comment(line):\n",
    "        if re.search(r\"^[#\\s()]\", line):\n",
    "            return 1\n",
    "\n",
    "    valid_symbols = list(filter(lambda text: len(text)>1 and not _is_comment(text), grammar_text.split(\"\\n\")))\n",
    "    cleaned_valid_symbols = list(map(lambda line: line.split(\"#\")[0].strip().split(\"\\t\"), valid_symbols))\n",
    "\n",
    "    grammar_hash = {}\n",
    "    for symbol in cleaned_valid_symbols:\n",
    "        if _is_terminal(symbol[2]):        \n",
    "            if symbol[1] not in grammar_hash:\n",
    "                grammar_hash[symbol[1]] = {str(symbol[2]): float(symbol[0])}\n",
    "                continue\n",
    "            grammar_hash[symbol[1]].update({str(symbol[2]): float(symbol[0])})\n",
    "            continue\n",
    "        else:\n",
    "            if symbol[1] not in grammar_hash:\n",
    "                grammar_hash[symbol[1]] = {tuple(map(str, symbol[2].split())): float(symbol[0])}\n",
    "                continue\n",
    "            grammar_hash[symbol[1]].update({tuple(map(str, symbol[2].split())): float(symbol[0])})\n",
    "            continue\n",
    "    return grammar_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1429ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_hash = _create_grammar_hash(grammar_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c36cb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar:\n",
    "    def __init__(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Context-Free Grammar (CFG) Sentence Generator\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to a .gr grammar file\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Parse the input grammar file\n",
    "        self.rules = None\n",
    "        self._load_rules_from_file(grammar_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def _spit_probable_choice(items, weights):\n",
    "        return random.choices(items, weights, k=1)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_tokens_to_sentence(tokens):\n",
    "        sentence = \" \".join(tokens)\n",
    "        sentence = re.sub(r\"\\s+([.!?])\", r\"\\1\", sentence)\n",
    "        sentence = re.sub(r\"\\s+'\", \"'\", sentence)\n",
    "        return sentence\n",
    "\n",
    "    def _load_rules_from_file(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Read grammar file and store its rules in self.rules\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to the raw grammar file \n",
    "        \"\"\"\n",
    "        def _is_comment(line):\n",
    "            if re.search(r\"^[#\\s()]\", line):\n",
    "                return 1\n",
    "\n",
    "        grammar_text = open(grammar_file, \"rb\").read().decode(\"utf-8\")\n",
    "\n",
    "        def _is_terminal(text):\n",
    "            return bool(re.search(terminal_pattern, text))\n",
    "\n",
    "\n",
    "        valid_symbols = list(filter(lambda text: len(text)>1 and not _is_comment(text), grammar_text.split(\"\\n\")))\n",
    "        cleaned_valid_symbols = list(map(lambda line: line.split(\"#\")[0].strip().split(\"\\t\"), valid_symbols))\n",
    "\n",
    "        grammar_hash = {}\n",
    "        for symbol in cleaned_valid_symbols:\n",
    "            if _is_terminal(symbol[2]):        \n",
    "                if symbol[1] not in grammar_hash:\n",
    "                    grammar_hash[symbol[1]] = {str(symbol[2]): float(symbol[0])}\n",
    "                    continue\n",
    "                grammar_hash[symbol[1]].update({str(symbol[2]): float(symbol[0])})\n",
    "                continue\n",
    "            else:\n",
    "                if symbol[1] not in grammar_hash:\n",
    "                    grammar_hash[symbol[1]] = {tuple(map(str, symbol[2].split())): float(symbol[0])}\n",
    "                    continue\n",
    "                grammar_hash[symbol[1]].update({tuple(map(str, symbol[2].split())): float(symbol[0])})\n",
    "                continue\n",
    "        self.rules = grammar_hash\n",
    "\n",
    "    def sample(self, derivation_tree, max_expansions, start_symbol):\n",
    "        \"\"\"\n",
    "        Sample a random sentence from this grammar\n",
    "\n",
    "        Args:\n",
    "            derivation_tree (bool): if true, the returned string will represent \n",
    "                the tree (using bracket notation) that records how the sentence \n",
    "                was derived\n",
    "            max_expansions (int): max number of nonterminal expansions we allow\n",
    "\n",
    "            start_symbol (str): start symbol to generate from\n",
    "\n",
    "        Returns:\n",
    "            str: the random sentence or its derivation tree\n",
    "        \"\"\"\n",
    "        \n",
    "        if start_symbol not in self.rules:\n",
    "            return start_symbol.strip()\n",
    "        \n",
    "        def _tree_expand(symbol, n_expansions=0):\n",
    "            if (symbol not in self.rules) or (n_expansions >= max_expansions):\n",
    "                tokens = symbol.split()\n",
    "                tree = symbol\n",
    "                return tokens, tree\n",
    "            \n",
    "            items = list(self.rules[symbol].keys())\n",
    "            weights = list(self.rules[symbol].values())\n",
    "            right_split = self._spit_probable_choice(items=items, weights=weights)\n",
    "            \n",
    "            if isinstance(right_split, tuple):\n",
    "                tokens_list, subtrees = [], []\n",
    "                for child in right_split:\n",
    "                    tokens, tree = _tree_expand(child, n_expansions+1)\n",
    "                    tokens_list.extend(tokens)\n",
    "                    subtrees.append(tree)\n",
    "                return tokens_list, f\"({symbol} {' '.join(subtrees)})\"\n",
    "            else:\n",
    "                return right_split.split(), f\"({symbol} {right_split})\"\n",
    "        \n",
    "        tokens, tree_str = _tree_expand(start_symbol)\n",
    "        if derivation_tree:\n",
    "            return tree_str\n",
    "        return self._convert_tokens_to_sentence(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar(grammar_file=\"grammar.gr\")\n",
    "grammar.sample(derivation_tree=True, max_expansions=10, start_symbol=\"ROOT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
